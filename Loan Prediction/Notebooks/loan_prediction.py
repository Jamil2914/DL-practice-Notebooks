# -*- coding: utf-8 -*-
"""Loan_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fbjzo3XHO3xq_7_c3bm7FT-xQeK_csLA
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
# %matplotlib inline

sklearn.__version__

data = pd.read_csv('preprocessed_loan_data.csv')

data.head()

data.dtypes

data.isnull().sum()

data = data.drop('Loan_ID',axis = 1)

data.head()

data.columns

data.shape

X = data.drop('Loan_Status',axis = 1)
y = data['Loan_Status']

X.shape , y.shape

#train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,stratify = data['Loan_Status'],random_state=10,test_size=0.2)

(X_train.shape,y_train.shape),(X_test.shape,y_test.shape)

import keras
import tensorflow as tf

keras.__version__

tf.__version__

from keras.models import Sequential
from keras.layers import InputLayer,Dense

X_train.shape

X_train.shape[1]

input_neurons = X_train.shape[1]

output_neurons = 1 # 1 output neuron binary classification

# number of hidden layers can be chosen at own as this is a hyperparameter
# number of neurons in hidden layers can also be chosen at own
number_of_hidden_layers = 2
neuron_hidden_layer_1 = 10
neuron_hidden_layer_2 = 5

"""### Defining the architecture of the model"""

model = Sequential()
# in hidden layers ReLu activation function has been used 
# as it is a binary classification problem thus sigmoid activation function is used for output layer
model.add(InputLayer(input_shape = (input_neurons,)))
model.add(Dense(units = neuron_hidden_layer_1,activation = 'relu'))
model.add(Dense(units = neuron_hidden_layer_2,activation='relu'))
model.add(Dense(units = output_neurons,activation='sigmoid'))

model.summary()



"""# Compiling the Model"""

model.compile(loss='binary_crossentropy',optimizer='Adam',metrics = ['Accuracy'])
#binary_crossentropy loss function for binary classification problems



"""# Training the model"""

model_history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 50)

"""## Testing and Evaluating"""

prediction = model.predict(X_test)
prediction = np.round(prediction).astype(int)

prediction

accuracy_score(y_test,prediction)

"""# Plottings"""

plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('model loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['train','validation'],loc = 'upper left')
plt.show()

plt.plot(model_history.history['Accuracy'])
plt.plot(model_history.history['val_Accuracy'])
plt.title('model accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['train','validation'],loc = 'upper left')
plt.show()

